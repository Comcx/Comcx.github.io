#+Title:  From Recursion to Greedy algorithms: a functional perspective
#+Author: Comcx
#+Date:   <2020-01-22 三>


There's an important leanring and developing chain of traditional algorithms:

=Divide and Conquer(recursion) ---> Dynamic Programming(mermorization) --> Greedy= 


This chain(route) is also quite suitble to get to think and solve a problem.
We may think problems in this way, but I sometimes just get confused if I insist on
following the rule. To collect our thinkings, programming languages play an really important role
in problem solving. Functional programming languages often work better for thinking but sometimes hard
to implement as efficiently as others. In fact, functional programming languages can also be very efficient
with careful implementation. As a programmer, we should get used to think in a more functional way and also,
be good at translate functional programs into other languages.


** Functional Programming とは ...
A functional programming language should have the following features:

1) Functions are first-class and thus can be passed as high-order function values.
2) Functions can be constructed without any side-effect.
3) Have both evaluation strategies: eager and lazy.


A functional programming language may have the following features:

1) Static and strict type system
2) Type polymorphism(type as type parameters)
3) Typeclass or trait(OO) system(u can also regard as structured overloading)
4) Pure without any side-effect(which means u can not survivie without monad:)
5) Dependent Typed System

** Divide and Conquer
Before starting to explore recursions, let us first reflect some questions:

1. What is data structure and what is a algorithm?
2. Any links between data structure and algorithms?
3. What kind of algorithm should we use for different kinds of data structures?

*** Data structures by Lists
In functional world, a very common and heavy used data structure is *List a(or [a] in haskell)*.
Let's look at its definition first:
#+BEGIN_SRC haskell

data List a = Nil | Cons a (List a)
#+END_SRC

**** Replacing
If we regard that =List= is just a function which receive a type and output a type, then we can rewrite
the definition(this is not strict...):
#+BEGIN_SRC 
List :: (a :: Type) -> Type where
  Cons :: a -> List a -> List a
  Nil  :: List a
#+END_SRC
We just defined 3 functions, this can be easily done with dependent typed languages.
For a simple list: =[1, 2, 3],= we can simply write it done:
#+BEGIN_SRC 
(Cons 1 (Cons 2 (Cons 3 Nil)))
#+END_SRC
Now we just replace all =Cons= into =(+)= and =Nil= into =0=.
#+BEGIN_SRC 
((+) 1 ((+) 2 ((+) 3 0))) => 1 + 2 + 3 + 0 => 6
#+END_SRC
We just turned a unfoldable(terminated form) into a foldable expression!
You may see that List is a prototype of many expressions, we can use this abstracted data structure
to generate more expressions without actually writing them character after charater!

Now define a replacing function:
#+BEGIN_SRC 
replace f a (Cons x xs) = f x (replace f a xs)
replace f a Nil = a
#+END_SRC
In fact, this function is called =foldr= in Haskell.
By using _Lists_, we can divide and store problems into many linear sub-problems, i.e.
To solve a problem, we only need to solve one sub-problem before.(this give us hint to convert this recursion to loops)

**** *Reversing lists*
One more interesting thing is that Haskell also have the function =foldl.= 
Then what's the differences between =foldr= and =foldl= ?

Lets again use our addition example.
#+BEGIN_SRC
xs = [0, 1, 2, 3] 
foldr (+) 0 xs => ((+) 0 ((+) 1 ((+) 2 ((+) 3 0)))) => (0 + 1 + 2 + 3 + 0)
foldl (+) 0 xs => ((+) ((+) ((+) ((+) 0 0) 1) 2) 3) => (0 + 0 + 1 + 2 + 3)
#+END_SRC

Compared with =foldr=, =foldl= is can be seen as a reversed list-constructed expression.
Let's try to implement our =foldl=:
#+BEGIN_SRC haskell

foldl f z [] = z
foldl f z (x:xs) = foldl f (f z x) xs
#+END_SRC

Great! Try to reverse a list using foldl:
#+BEGIN_SRC haskell

reverse = foldl (flip (:)) []
#+END_SRC

**** foldl or foldr?
1) If we are in a stack model, then foldl can be used without worrying about stackoverflow.
2) Both are valid if we have the rule: (f a (f b c)) = (f (f a b) c). In other words, the type a in =List a= should
   be an instance of typeclass _Monoid_.

*** Expressions
In the last part, we talked about data structures. However, a new question raised that,
What exactly is an expression??

Let's first get a simple definition.
#+BEGIN_SRC 
An expression is any valid unit of code that resolves to a value.
#+END_SRC
Well, this looks still not enough straight-forward answer.
If so, then what is value??

Before we have the ability and knowledge to answer these questions, let's firstly introduce some
necessary terminologies.

- *Thunk*
#+BEGIN_SRC 
A thunk is another name for the function(but the special one).
It's a function yet to be evaluated.
For example, in Haskell, every expression is lazy and be stored into a thunk.
#+END_SRC

- *Beta reduction*
#+BEGIN_SRC 
Beta reduction is a process of calculating result of a function after function application.
We can now simple regard this process as a special replacing of introduced local variables.
#+END_SRC

Ok! Now let's explore it! What is a value?
Firstly I guess /value/ is the form that can not be calculated further.
If I'm right... what about ...

*Definition of Redeuced Normal Form(RNF)* 
#+BEGIN_SRC 
Expression A has RNF if there exists term B obtained from A that is in RNF and B is in RNF where 
there’s no term A such A can be obtained from B and A has RNF.
#+END_SRC
To make my life easier, RNF is the form whose sub-expressions(including itself) can not be reduced any further.

*(Head) Normal Form*
#+BEGIN_SRC 
An expression in (Head)normal form is fully evaluated, and no sub-expression could be evaluated any further.
#+END_SRC
Well, seems similar to RNF. Next form is quite important:

*Weak Head Normal Form(WHNF)*
#+BEGIN_SRC 
An expression is in weak head normal form when the outermost part has been evaluated to 
the data constructor or lambda abstraction. Sub-expressions may not have been evaluated. 
If all the sub-expressions would be evaluated then the expression would be in normal form. 
The conclusion is: every normal form expression is also in weak normal form. The opposite is not always the true.
#+END_SRC
for example:
#+BEGIN_SRC 
(1 + 1, 1 + 2)      
'h' : ("e" ++ "llo")
\x -> 2 + 2 
#+END_SRC

Alright, we've got the point of Haskell's lazy evlauation strategy.
In Haskell, expressions are evaluated until they are in need.
To be more precise, "in need" means we need to do pattern matching by data constructors.

Now I suppose I was wrong. Value should not be just expressions can not be evaluated further.
In lazy languages, it can also means _weak head normal form_.

Finally we feel that we've got better understanding of expressions...(although still confusing and error-prone)

*** Data structures by Trees
Unlike /Lists,/ Trees allow us to divide problems into many sub-problems.
To make things simple and clear, we first focus on _binary trees_.

**** Binary Tree
#+BEGIN_SRC haskell

data BinTree a = Empty | Node a (BinTree a) (BinTree a)
#+END_SRC
Again this data strucutre is a prototype for recursion algorithms.
Now we create an example and try to do the same things as /Lists/.

- An example of Binary Tree
#+BEGIN_SRC 
tree :: BinTree Int
tree = Node 0
         (Node 1 Empty Empty)
         (Node 2 
           (Node 3 Empty
                  (Node 4 Empty Empty))
           (Node 5 
             (Node 6 Empty Empty)
             (Node 7 Empty Empty)))
#+END_SRC
  + Visualization
#+BEGIN_SRC 
           0
    1             2
             3         5
               4     6   7
#+END_SRC

- Replacing(folding)
We want to do the replacing thing as Lists do.
Observe that this time we may have more parameters to replace:
  1. Node
  2. Empty
  3. ??
If the function to replace =Node= is binary(a -> b -> b), then we need the third pararmeter to combine
sub-trees.
Else, the third para is not necessary.

- A naive replacing
#+BEGIN_SRC haskell

replace f z Empty = z
replace f z (Node v t0 t1) = f v (replace f z t0) (replace f z t1)
#+END_SRC
  + Visualization of the example
#+BEGIN_SRC 
f 0 (f 1 z z)
    (f 2 (f 3 z 
              (f 4 z z))
         (f 5 (f 6 z z)
              (f 7 z z)))
#+END_SRC

Now we can add all numbers of =BinTree Int=.
#+BEGIN_SRC haskell

sum = replace (\v a b -> v + a + b) 0
#+END_SRC

***** Using tricks as foldl in Lists
If we want to traverse a binary tree in an inorder order:

- Naive inorder traverse
#+BEGIN_SRC haskell

inorder Empty = []
inorder (Node v t0 t1) = inorder t0 ++ [v] ++ inorder t1
#+END_SRC
This is valid but not efficient for too many append operations.
Let's try to do some expression transformations:
#+BEGIN_SRC haskell

inorder' t@(Node v t0 t1) a = inorder t ++ a
  = inorder t0 ++ [v] ++ inorder t1 ++ a
  = inorder to ++ (v:(inorder' t1 a))
  = inorder' t0 (v:(inorder' t1 a)) 
#+END_SRC
Finally we have:
#+BEGIN_SRC haskell

inorder' t = inorder'' t [] where
  inorder'' Empty z = z
  inorder'' (Node v t0 t1) z = inorder'' t0 (v:(inorder'' t1 a)) 
#+END_SRC

**** More general trees
#+BEGIN_SRC haskell

data Tree a = Node a [Tree a]
#+END_SRC
Now we have the prototype to handle all recursion problems!

- Folding
#+BEGIN_SRC haskell

fold f z (Node v []) = f v [z]
fold f z (Node v ts) = f v $ map (fold f z) ts
#+END_SRC
or
#+BEGIN_SRC haskell

fold' f g z (Node v []) = f v z
fold' f g z (Node v ts) = f v $ (g $ map (fold' f g z) ts)
#+END_SRC

*** The answers
OK! now I may answer the three questions before(may be wrong, only my views):

**** What is data structure?
Data structures are recursion proto structures which can be used to solve problems.

**** What is algorithm?
Algorithms are _foldable_ data structures.

**** Links between data structures and algorithms?
Data structures can be easily converted to algorithms.
Algorithms can be used to generate data structures.

**** How to select?
To select data structures with respect to different kind os algorithms,
We should choose data structures which have the same recursion structure as the algorithm
as far as possible.

*** Abstract Data Types [4/7]
In fact, data structures we talked before are _Algebra Data Structures(ADT)_.
However, we can generize our types a little bit, we can define types by actions.

**** DONE Stack
The =Stack= implementation is quite straight-forward.
#+BEGIN_SRC haskell

class Stack s where
  push       :: a -> s a -> s a
  pop        :: s a -> s a
  top        :: s a -> a
  emptyStack :: s a

newtype Stk a = Stk [a]

instance Stack Stk where
  push x (Stk xs) = Stk (x:xs)

  pop (Stk [])     = error "Empty stack!"
  pop (Stk (_:xs)) = Stk xs

  top (Stk [])    = error "Empty stack!"
  top (Stk (x:_)) = x

  emptyStack = Stk []
#+END_SRC
Each step is in =O(1)= steps.

**** DONE Queue
#+BEGIN_SRC haskell

class Queue q where
  enqueue    :: a -> q a -> q a
  dequeue    :: q a -> q a
  front      :: q a -> a
  emptyQueue :: q a
#+END_SRC
***** A naive implementation
#+BEGIN_SRC haskell

newtype Que a = Q [a]

instance Queue Que where
  enqueue x (Q q) = Q (q ++ [x])

  dequeue (Q [])     = error "Empty queue!"
  dequeue (Q (_:xs)) = Q xs

  front (Q [])    = error "Empty queue!"
  front (Q (x:_)) = x

  emptyQueue = Q []
#+END_SRC
=enqueue= takes =O(n)= steps.

***** Another implementation
#+BEGIN_SRC haskell

-- Another implementation by Burton
newtype Que a = Q ([a], [a])

instance Queue Que where
  enqueue x (Q ([], [])) = Q ([x], [])
  enqueue y (Q (xs, ys)) = Q (xs, y:ys)

  dequeue (Q ([], []))   = error "Empty queue!"
  dequeue (Q ([], ys))   = Q (tail (reverse ys), [])
  dequeue (Q (x:xs, ys)) = Q (xs, ys)

  front (Q ([], []))   = error "Empty queue!"
  front (Q ([], ys))   = last ys
  front (Q (x:xs, ys)) = x

  emptyQueue = Q ([], [])
#+END_SRC
- /Note/: Okasaki describes a method in which a list is reversed prograssively during dequeue
  operations so that the worest case for any dequeue operation is in =O(logn)=.

***** Priority queue
A priority queue is a queue in which each item has a priority associated with it.
The =dequeue= operation always removes the item with the highest(or lowest) priority.

****** A naive implementation
#+BEGIN_SRC haskell

newtype PQueue a = PQ [a]

instance Queue PQueue where
  emptyQueue = PQ []
  
  enqueue x (PQ q) = PQ (insert x q) where
    insert x [] = [x]
    insert x r@(e:r')
      | x <= e    = x:r
      | otherwise = e:insert x r'

  dequeue (PQ [])     = error "Empty queue!"
  dequeue (PQ (x:xs)) = PQ xs

  front (PQ [])     = error "Empty queue!"
  front (PQ (x:xs)) = x
#+END_SRC

****** Implementation with heap

**** TODO Heap
**** NEXT Set
#+BEGIN_SRC haskell

class Set s where
  emptySet :: S a
  inSet    :: (Eq a) => a -> s a -> Bool
  addSet   :: (Eq a) => a -> s a -> s a
  delSet   :: (Eq a) => a -> s a -> s a
#+END_SRC

***** List implementations

**** CANCELLED Vector
**** CANCELLED Table
**** NEXT More Trees [1/3]
***** DONE Binary Search Tree
- Definition
#+BEGIN_SRC haskell

{-# LANGUAGE GADTs #-}
data BinTree a where
  None :: Ord a => BinTree a
  Node :: Ord a => a -> BinTree a -> BinTree a -> BinTree a
#+END_SRC

- Finding elements

Very straight-forward =O(logn)=.
#+BEGIN_SRC haskell

inTree x None = False
inTree x (Node v lf rt)
  | x == v = True
  | x <  v = inTree x lf
  | x >  v = inTree x rt
#+END_SRC


- Adding items

Very straight-forward =O(logn)=.
#+BEGIN_SRC haskell

addTree x None = Node x None None
addTree x t@(Node v lf rt)
  | x == v = t
  | x <  v = Node v (addTree x lf) rt
  | x >  v = Node v lf (addTree x rt)
#+END_SRC


- Building

#+BEGIN_SRC haskell

-- A naive building function
buildTree lf = foldr addTree None lf
#+END_SRC
However, this implementation may produce unbalanced tree.
It's possible to build a tree with a minimum depth:

#+BEGIN_SRC haskell

buildTree' []  = None
buildTree' lf  = Node x (buildTree' l1) (buildTree' l2)
  where l1     = take n lf
        (x:l2) = drop n lf
        n      = (length lf) `div` 2
#+END_SRC

- Removing an item
#+BEGIN_SRC haskell

delTree x None = None
delTree x (Node v lf None)
  | x == v = lf
delTree x (Node v None rt)
  | x == v = rt
delTree x (Node x lf rt)
  | x <  v = Node v (delTree x lf) rt
  | x >  v = Node v lf (delTree x rt)
  | x == v = Node k lf (delTree k rt) where 
    k = minTree rt
    minTree (Node v None _) = v
    minTree (Node _ left _) = minTree left
#+END_SRC

***** TODO AVL Tree
***** TODO Red-black Tree

** Dynamic Programming
Dynamic programming is about finding similar sub structures.

*** A dynamic programming example by expanding data structure
Suppose we want to insert a node at the lowest level of the smallest sub-tree.
(Binary Tree definition just as before)
#+BEGIN_SRC haskell

tinsert v Empty = Node v Empty Empty
tinsert v (Node w t0 t1)
  | size t0 <= size t1 = Node w (tinsert v t0) t1
  | otherwise          = Node w t0 (tinsert v t1)
#+END_SRC
We can see that the function =size= is used several times and it seems that there're
relations between levels of sub-trees that can be used to calculate the size more efficiently.

An alternative is to use the following tree definition instead:
#+BEGIN_SRC haskell

data BinTreeM a 
  = EmptyM 
  | NodeM (Int, Int) a (BinTreeM a) (BinTreeM a)

tinsertM v EmptyM = NodeM (0, 0) v EmptyM EmptyM
tinsertM v (NodeM (s0, s1) w t0 t1)
  | s0 <= s1  = NodeM (s0 + 1, s1) w (tinsertM v t0) t1
  | otherwise = NodeM (s0, s1 + 1) w t0 (tinsertM v t1)
#+END_SRC

However, you may think that this example is not a right dynamic programming example.
So let's take more examples.

*** A dynamic programming example by using extra data structure
A well-known data structre used frequently in dynamic programming is =Array=.


** Greedy





